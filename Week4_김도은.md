### Paper Details
- **Title**: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale
- **Authors**: Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby
- **Conference**: International Conference on Learning Representations (ICLR 2021)
- **Year of Publication**: 2021
- **Link**:[https://arxiv.org/abs/2010.11929](https://arxiv.org/abs/2010.11929)
- **Key Focus**: This paper introduces the Vision Transformer (ViT), which applies the transformer model, traditionally used in NLP tasks, directly to image patches for image recognition. It eliminates the reliance on convolutional networks and demonstrates that transformers, pre-trained on large-scale datasets and fine-tuned for smaller image recognition tasks, can outperform convolutional neural networks (CNNs) such as ResNet. By training on large datasets like ImageNet-21k and JFT-300M, ViT achieves state-of-the-art results on benchmarks such as ImageNet, CIFAR-100, and VTAB. The model handles image classification tasks with fewer computational resources, and its performance improves as the dataset size increases. ViT achieves an accuracy of 88.55% on ImageNet, 94.55% on CIFAR-100, and 77.63% on VTAB tasks.

### Link
üìù [[ÎÖºÎ¨∏ Î¶¨Î∑∞] AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE](https://dony-archive.tistory.com/32)
